{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7930435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as pr\n",
    "# import PyPDF3\n",
    "# import PyPDF4\n",
    "# import pandas as pd\n",
    "# import textract\n",
    "# import autocorrect\n",
    "# from autocorrect import Speller\n",
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323f9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import re\n",
    "# import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1445ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    reader = PyPDF2.PdfReader(file_path)  #read the pdf file using PyPDF2\n",
    "    \n",
    "    for i in range(len(reader.pages)):   #reader.pages will give the number of pages present in the pdf_file\n",
    "        #iterating the number pages and reading the text page wise\n",
    "        page = reader.pages[page_num]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a364ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pages(target_pdf_file: str):\n",
    "    pdf_file_obj = open(target_pdf_file, 'rb')\n",
    "    pdf_reader = pr.PdfReader(pdf_file_obj)\n",
    "    return pdf_reader.numPages\n",
    "\n",
    "# def retrieve_text(pdf_path):\n",
    "    \n",
    "#     with open(pdf_path, 'rb') as file:\n",
    "        \n",
    "#         reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "#         # Initialize an empty string to store the extracted text\n",
    "#         text = \"\"\n",
    "        \n",
    "#         # Iterate through each page in the PDF\n",
    "#         for page_num in range(len(reader.pages)):\n",
    "#             # Get the page object\n",
    "#             page = reader.pages[page_num]\n",
    "            \n",
    "#             # Extract text from the page\n",
    "#             text += page.extract_text()\n",
    "        \n",
    "#         return text\n",
    "\n",
    "# # Path to the PDF file\n",
    "# pdf_path = input('Write the file path:')\n",
    "\n",
    "# # Call the function to extract text from the PDF\n",
    "# extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# # Print the extracted text\n",
    "# print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of supported languages and their ISO 639-2 language codes\n",
    "supported_languages = {\n",
    "    'English': 'eng',\n",
    "    'French': 'fra',\n",
    "    'German': 'deu',\n",
    "    'Spanish': 'spa',\n",
    "    'Portuguese': 'por',\n",
    "    'Italian': 'ita',\n",
    "    'Dutch': 'nld',\n",
    "    'Russian': 'rus',\n",
    "    'Chinese (Simplified)': 'chi_sim',\n",
    "    'Chinese (Traditional)': 'chi_tra',\n",
    "    'Japanese': 'jpn',\n",
    "    'Korean': 'kor',\n",
    "    'Arabic': 'ara',\n",
    "    'Finnish': 'fin',\n",
    "    'Swedish': 'swe',\n",
    "    'Danish': 'dan',\n",
    "    'Norwegian': 'nor',\n",
    "    'Polish': 'pol',\n",
    "    'Hungarian': 'hun',\n",
    "    'Turkish': 'tur',\n",
    "    'Czech': 'ces',\n",
    "    'Greek': 'ell',\n",
    "    'Thai': 'tha',\n",
    "    'Hebrew': 'heb',\n",
    "    'Hindi': 'hin',\n",
    "    'Tamil': 'tam',\n",
    "    'Urdu': 'urd',\n",
    "    'Vietnamese': 'vie'\n",
    "}\n",
    "\n",
    "# Prompt the user to select a language\n",
    "print(\"Select a language:\")\n",
    "for idx, lang in enumerate(supported_languages.keys(), 1):\n",
    "    print(f\"{idx}. {lang}\")\n",
    "\n",
    "selected_language_idx = int(input(\"Enter the number corresponding to the language: \"))\n",
    "\n",
    "# Validate user input\n",
    "if selected_language_idx < 1 or selected_language_idx > len(supported_languages):\n",
    "    print(\"Invalid input. Please enter a valid number.\")\n",
    "else:\n",
    "    # Get the selected language\n",
    "    selected_language = list(supported_languages.values())[selected_language_idx - 1]\n",
    "    print(f\"You selected: {list(supported_languages.keys())[selected_language_idx - 1]} ({selected_language})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of supported languages and their ISO 639-2 language codes\n",
    "supported_languages = {\n",
    "    'English': 'eng',\n",
    "    'French': 'fra',\n",
    "    'German': 'deu',\n",
    "    'Spanish': 'spa',\n",
    "    'Portuguese': 'por',\n",
    "    'Italian': 'ita',\n",
    "    'Dutch': 'nld',\n",
    "    'Russian': 'rus',\n",
    "    'Chinese (Simplified)': 'chi_sim',\n",
    "    'Chinese (Traditional)': 'chi_tra',\n",
    "    'Japanese': 'jpn',\n",
    "    'Korean': 'kor',\n",
    "    'Arabic': 'ara',\n",
    "    'Finnish': 'fin',\n",
    "    'Swedish': 'swe',\n",
    "    'Danish': 'dan',\n",
    "    'Norwegian': 'nor',\n",
    "    'Polish': 'pol',\n",
    "    'Hungarian': 'hun',\n",
    "    'Turkish': 'tur',\n",
    "    'Czech': 'ces',\n",
    "    'Greek': 'ell',\n",
    "    'Thai': 'tha',\n",
    "    'Hebrew': 'heb',\n",
    "    'Hindi': 'hin',\n",
    "    'Tamil': 'tam',\n",
    "    'Urdu': 'urd',\n",
    "    'Vietnamese': 'vie'\n",
    "}\n",
    "\n",
    "# Prompt the user to select a language\n",
    "print(\"Select a language:\")\n",
    "for idx, lang in enumerate(supported_languages.keys(), 1):\n",
    "    print(f\"{idx}. {lang}\")b\n",
    "\n",
    "user_input = input(\"Enter the number or name of the language: \")\n",
    "\n",
    "# Check if the user input is a number\n",
    "if user_input.isdigit():\n",
    "    selected_language_idx = int(user_input)\n",
    "    if selected_language_idx < 1 or selected_language_idx > len(supported_languages):\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "    else:\n",
    "        # Get the selected language\n",
    "        selected_language = list(supported_languages.values())[selected_language_idx - 1]\n",
    "        print(f\"You selected: {list(supported_languages.keys())[selected_language_idx - 1]} ({selected_language})\")\n",
    "else:\n",
    "    # Convert the user input to lowercase for case insensitivity\n",
    "    user_input_lower = user_input.lower()\n",
    "    # Check if the user input matches any language name\n",
    "    if user_input_lower in [lang.lower() for lang in supported_languages.keys()]:\n",
    "        selected_language = supported_languages[[lang.lower() for lang in supported_languages.keys()].index(user_input_lower)]\n",
    "        print(f\"You selected: {selected_language} ({supported_languages[selected_language]})\")\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a valid number or language name.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97994c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    'English': 'eng',\n",
    "    'French': 'fra',\n",
    "    'German': 'deu',\n",
    "    'Spanish': 'spa',\n",
    "    'Portuguese': 'por',\n",
    "    'Italian': 'ita',\n",
    "    'Dutch': 'nld',\n",
    "    'Russian': 'rus',\n",
    "    'Chinese (Simplified)': 'chi_sim',\n",
    "    'Chinese (Traditional)': 'chi_tra',\n",
    "    'Japanese': 'jpn',\n",
    "    'Korean': 'kor',\n",
    "    'Arabic': 'ara',\n",
    "    'Finnish': 'fin',\n",
    "    'Swedish': 'swe',\n",
    "    'Danish': 'dan',\n",
    "    'Norwegian': 'nor',\n",
    "    'Polish': 'pol',\n",
    "    'Hungarian': 'hun',\n",
    "    'Turkish': 'tur',\n",
    "    'Czech': 'ces',\n",
    "    'Greek': 'ell',\n",
    "    'Thai': 'tha',\n",
    "    'Hebrew': 'heb',\n",
    "    'Hindi': 'hin',\n",
    "    'Tamil': 'tam',\n",
    "    'Urdu': 'urd',\n",
    "    'Vietnamese': 'vie'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2465ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e184ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-27ddd10295a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.values()\n",
    "user_input = 'ENG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ff9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(a.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b35439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_text(pdf_path):\n",
    "    \n",
    "#     with open(pdf_path, 'rb') as file:\n",
    "        \n",
    "#         reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "#         # Initialize an empty string to store the extracted text\n",
    "#         text = \"\"\n",
    "        \n",
    "#         # Iterate through each page in the PDF\n",
    "#         for page_num in range(len(reader.pages)):\n",
    "#             # Get the page object\n",
    "#             page = reader.pages[page_num]\n",
    "            \n",
    "#             # Extract text from the page\n",
    "#             text += page.extract_text()\n",
    "        \n",
    "#         return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in b:\n",
    "    if i == user_input.lower():\n",
    "        user_input = user_input.lower()\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "039a3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = ('Sudhanshu_sharma_resume.pdf')\n",
    "pdf_file_obj = open(pdf_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "014bb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pr.PdfReader(pdf_file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba56a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "c = len(reader.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4753298",
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecationError",
     "evalue": "getDocumentInfo is deprecated and was removed in PyPDF2 3.0.0. Use metadata instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDeprecationError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e5e4348cb367>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDocumentInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_reader.py\u001b[0m in \u001b[0;36mgetDocumentInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mUse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mdeprecation_with_replacement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"getDocumentInfo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"3.0.0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_utils.py\u001b[0m in \u001b[0;36mdeprecation_with_replacement\u001b[1;34m(old_name, new_name, removed_in)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[0mRaise\u001b[0m \u001b[0man\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mthat\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mwas\u001b[0m \u001b[0malready\u001b[0m \u001b[0mremoved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mhas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[0mdeprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEPR_MSG_HAPPENED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremoved_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_utils.py\u001b[0m in \u001b[0;36mdeprecation\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mDeprecationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDeprecationError\u001b[0m: getDocumentInfo is deprecated and was removed in PyPDF2 3.0.0. Use metadata instead."
     ]
    }
   ],
   "source": [
    "    reader.getDocumentInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d69b050",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PdfReader' object has no attribute 'extract_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8959f9dcee26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PdfReader' object has no attribute 'extract_text'"
     ]
    }
   ],
   "source": [
    "print(reader.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41a0927f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PdfReader' object has no attribute 'extract_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-0519e9c3a755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sudhanshu_sharma_resume.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PdfReader' object has no attribute 'extract_text'"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"Sudhanshu_sharma_resume.pdf\")\n",
    "page = reader.pages[0]\n",
    "print(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1fe09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ec6279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(d):\n",
    "    po = reader.pages[i]\n",
    "    text = po.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b57ca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "Experienced professional with 1.5+ years of banking industry exposure and a background as a certified data analyst. Currently thriving as a PL/SQL Developer, leveraging\n",
      "my analytical skills to drive user growth and enhance user retention. Proficient in performing in-depth data analysis to provide actionable insights, facilitating sound\n",
      "decision-making, and producing error-free reports. Additionally, skilled in data mining and data visualization, delivering valuable business solutions to clients and\n",
      "consistently achieving project success.\n",
      "KEY SKILLS\n",
      "• Data Analysis • Stakeholder Management • Software Development  • Quality Assurance • Data Mining • Leadership & Training • Process Improvement \n",
      "                             • Data Visualization • SQL Expertise • Problem-Solving  • Performance Tuning • Agile/Scrum • ETL (Extract, Transform, Load) \n",
      "            • Capital Markets  • Programming  • Big Data  • Data Engineering • Machine Learning Methodologies • RDBMS  • NOSQL Databases  • Data Warehouses \n",
      "TECHNICAL SKILLS\n",
      "IIIT Bangalore: Spark, Python, SQL, Hive, Tableau, Hadoop, NOSQL, PLSQL, Apache Redshift, Unix/Linux, EC2, EMR, Bitbucket, Bamboo, JIRA, Git/Github,         \n",
      "  Apache HBase, Apache Flume, Apache Sqoop, Pyspark, Spark, SparkSQL, MS Excel (Advance)\n",
      "Cloud: Amazon AWS\n",
      "Database: Oracle 11g/19c, MS SQL Server, MySQL \n",
      "PROFESSIONAL EXPERIENCE\n",
      "Software Engineer -\n",
      "LTIMINDTREE\n",
      "Key Responsibilities-\n",
      "Data and Code Analysis:\n",
      "Development and Coding:\n",
      "Communication and Presentation:\n",
      "Quality Assurance and Improvement:\n",
      "KEY PROJECTS\n",
      "      Technology Stack - Python, Pandas, NumPy, Pandas, Matplotlib, \n",
      "      Seaborn,  Statsmodels, Scikit-learn\n",
      "      Domain - Finance\n",
      "      Description - This case study aims to build a Multiple Linear Regression model for the prediction of demand for shared bikes in the USA.\n",
      "      Technology Stack - Python, Pandas, NumPy, Matplotlib, Seaborn\n",
      "      Domain - Banking\n",
      "      Description- This case study aims to identify patterns which indicate if a client has difficulty paying their installments which may be used for taking actions such         \n",
      "      as denying the loan, reducing the amount of loan. In this case study we perform data visualization and data cleaning with the help of PYTHON.\n",
      "      Technology Stack - Python, Pandas, NumPy, Matplotlib, Seaborn\n",
      "      Domain - Banking\n",
      "      Description- This case study aims to perform the EDA on the given dataset to analyse the patterns and provide inferences/solutions for the future marketing \n",
      "      campaign.\n",
      "EDUCATION\n",
      "Post Graduate Diploma in Data Science -\n",
      "IIIT Bangalore\n",
      "Bachelor of Computer Application -\n",
      "MCU,Bhopal\n",
      "ADDITIONAL INFORMATIONSudhanshu Sharma\n",
      "+91 9582590543 sudhanshusharma168@gmail.com Delhi,IN www.linkedin.com/in/sudhanshusharma168\n",
      "Mar '22 Present\n",
      "Navi Mumbai, IN\n",
      "Coproduce in-depth data and code analysis to understand complex business requirements •\n",
      "Create and implement complex SQL queries and data manipulation operations to meet project objectives •\n",
      "Develop and maintain PL/SQL code components, including cursors, procedures, packages, triggers, and functions •\n",
      "Drive the design and development of efficient database solutions to support critical business processes •\n",
      "Ensure data integrity, security, and compliance with best practices in database development •\n",
      "Collaborate with cross-functional teams to translate technical requirements into actionable solutions for business stakeholders •\n",
      "Convey findings and solutions to business stakeholders in a clear and comprehensible manner •\n",
      "Participate in code reviews, debugging, and troubleshooting to maintain code quality and performance •\n",
      "Stay current with emerging technologies and industry trends to continuously improve coding practices and database development processes •\n",
      "Bike Rental Case Study •\n",
      "CREDIT EDA CASE STUDY •\n",
      "BANK MARKETING DATA ANALYSIS •\n",
      "Jul '21 Aug '22\n",
      "Bengaluru, IN\n",
      "Course Modules: •\n",
      "Data Analysis using SQL | Introduction to Python | Introduction to Machine Learning and Linear Regression ○\n",
      "IMDB Movie Case Study | Telecom Churn Case Study ○\n",
      "Business Problem Assignment | Building Automated Data Pipelines with Oozie/Airflow | Analytics using PySpark ○\n",
      "Secured 3.85 GPA •\n",
      "Jul '17 Oct '20\n",
      "New Delhi, IN\n",
      "Secured 7.9 CGPA •\n",
      "Languages - English (Professional FLuency), Spanish (Intermmediate), Hindi (Native) •\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "529ec7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sudhanshu\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sudhanshu\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\users\\sudhanshu\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\sudhanshu\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\sudhanshu\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea4881fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SUDHANSHU/nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-02514bef578b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [\n\u001b[0;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SUDHANSHU/nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SUDHANSHU\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text.lower(), 'eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab047ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "exl = pd.DataFrame(property_information,index=[0])\n",
    "exl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
